Perception and time in Artificial Intelligence.
Andrey Makushkin
toandrey@yahoo.com
March 24, 2019


Summary:
Intelligence is an emergent behavior attributed to entities posessing mechanisms such as perception, short and long term memory, ability to learn or forget, attention, habbituation, reflexes, actuation.  Perception is considered one of the most important by many researchers.[1][2]

Perception is detection of an internal state change described in terms of time.  Detection of state change should not be described by changing the state.  This paper tries to explain this statement through examples and references to existing literature as well as elaborate on the implications.  For example above definition makes it possible to think about observer as a process not an object.  Another goal is to underline the importance of studying time aspects of computational mechanisms.  For example modeling synapses as oscillators or processes instead of weights.


Introduction:
Current widely accepted definition of perception can be summarized as "perception is a change in internal state as a result of external stimuli".  A better description takes time into account lets say by including patterns of temporal-spacial neural activations.  Author will refrain from providing references to these definitions. I will simply provide a counter-example: a rock's internal state can be changed by heating it.  It will have a short term memory of it because it remains hot for some time.
It can form dazzling patterns and crystalline structures. Reflects or absorbs light, conducts or insulates electric currents. Geologist have made careers out of studying long term memories of the rocks. It can also actuate by falling on a passer-by's head as a result of changing its state. However taking all that complex behavior into account I hope no one will claim that the rock can perceive it's environment.  If you believe that the rock example is irrelevant, just remember that a CCD sensor's wafer is made of silica.
On the other hand inside a neuron a different process takes place. Neuron's state (it's membrane potential) is changed by external stimuli. External stimula constitutes sensory stimula or other neurons firing.  When membrane potential reaches a certain voltage level it is detected and neuron fires. Average neuron threshold potential is about -55mv.

Misunderstanding that state can describe perception is a result of the state-oriented view of the world as opposed to process-oriented. In the process-oriented view a change in a process can be described by when it happened as opposed to <REWISE> a symbol changing from A to B in the state-oriented view. In this case symbol can represent any property or quantity.


Perception in philosophy:
Before proceeding to explain how perception relates to Artificial Intelligence, lets review some historical views on perception. One of the first well known models of perception are Plato's theory of forms and his "Allegory of the Cave". The theory is about 1500 years old and withstood the test of time.  Plato describes objects being perceived as shadows without ever knowing their true form.  He also adds that a true philosopher thinks in terms of forms.

<ADD TRANSITION>
Change in temperature freezes the lake not the cold itself.  The fact that it's cold can tell us about the state of the lake being frozen. Only the change in temperature can describe that the state of the lake is changing. 

<TIE in with manchester encoding???>

<ADD>
Brightness of a pixel (red 34) VS one pixel brighter than the other (A>B). Which carries more information?

Now is the best answer. All information available up to now has been considered.
What action should I perform right now? vs Should I perform a specific action right now?  Both approarches try to answer what the sequence of actions should be.



Measuring and numbers:
What is the difference between 20 and 68?  None, because 20 degrees Celsius is 68 degrees Fahrenheit.  Is five equals five? No, because five inches are longer than five centimeters.  Values are meaningless without units.  Talking about units leads to the problem of Qualia.

On the other hand there is a problem of comparing apples to oranges.  If the units do not match, things can not be related.

Values are measures of an object's state from an absolute reference point such as zero.  The reference point and scale usually have nothing to do with the object whos properties are measured.  They are qualities of an observer.  Values can also measure a change in an object's state or the rate of change.  

Any observer cannot directly measure the state of an object such as its color or temperature.  It can only observe changes. [REFERENCES?]  A photon arriving at the retina, hair deflecting in a cochlea, tactile input, molecule locking into a receptor in the nose, they are all events occuring in the sensor's environment.  When we are looking at observations expressed in terms of values we are frequently looking at the number of events per unit of time.  Ironically Quantification, a concept that has to give meaning to observation is the reason observations lose their grounding.[5] 

Measuring the state of the environment produces symbols frequently expressed as numbers in digital systems. 
<TIE in> It forms a symbolic world representation.

Numbers are projections of real world penomena onto an axis. They are shadows. Every time a measurement is made, a shadow is produced. What are the alternatives you ask? In Plato's terms they are forms.  Forms can not be measured, described as a symbol, or transmitted.  Forms can only be detected.  This closely relates to the problem of qualia which can not be expressed symbolicaly.  Qualia is perception of a form.

<TIE in>
Time instance is the smallest quanta of information yet since time is continuous its resolution is limited only by an observer's precision.


Perception in Artificial Intelligence:
First memorable mention of perception in AI has to be attributed to Frank Rosenblatt.  In his 1957 paper "The Perceptron A receiving and recognizing automaton" he puts perception first in the list of "human-like functions". He also references Platos' forms. "the form of a man seen from any angle" However this reference has been greatly overlooked along with his mention of inhibiting connections not included in the current perceptron definition. He writes about his "Sensory System" which we now call the input layer "any connection may be negative (tending to inhibit)". In addition Rosenblatt emphasises importance of time by dividing perceptrons in two categories: "momentary stimulus perceptrons and temporal pattern perceptrons".

Where as Rosenblatt wanted his perceptrons to detect the forms, now days we have a more generic word for mechanisms of perception to detect forms.  They are called features.  A feature is a mechanism of perception.  Features can be detected by current models and even used in a generative mode to create  pictures.  Features can be used in a generative mode because they embed information into it's definition.

Feature is an accidental discovery.  It's importance as a mechanism of perception that can make real world observations in terms of time is not well known.  <REWISE> For example, success of LSTM algorithm can be attributed to implementing a clever timing mechanism.  This mechanism allows procesing of stimuli from different time periods.  Instead of making researchers concentrate on the time aspect of the computational models, this hack gained wide acceptance as-is.   Another big problem is if you train any supervised learning algorithm to give you a prediction one day in the future, it will not be able to predict what happens in an hour. This fact itself is counterintuitive. At first it might appear that making an algorithm an on-line learning algorithm might solve the problem.
<ADD from PHONE AI.txt "turn based games">
There are two types of AI: a static world, turn based and dynamic world AI.  In a dynamic world a process or processes are observed. Time is a fundamental description of the perceived state of the process (signals). In static world AI, a system is presented with data without a time component.  Such as in turn-based games, pattern recognition etc. Static world AI can be tricked to perform on dynamic world problems by sying take turn every few milliseconds or run every time a sensor is read. This approach can be used in robotics.


Zeros and Ones used in ANNs are not symbols. They are flags that signify <belonging> to a time period.  There are problems with this way of representing time. Some of them are described in "Finding Structure In Time" paper by Jeffrey L. Elman.  However the important thing is to understand they represent time.  By doing so they avoid the "Symbol Grounding Problem" inherent in symbolic systems.

<EDIT>
Connectionism does not explain this. In addition it does not explain <insert reference to many neuro transmitters>
connectivism does not specify that functionally Sensory neurons are the same as internal neurons they are both detectors

Are features the answer to perception? In many current models feature detection or absense is represented symbolically as 0 or 1. The problem with that is the "Symbol Grounding Problem".

Symbol grounding problem should not be just a red flag for symbolic AI but a red brick wall for any approach that uses state in it's computation model. <DELETE?> Some researchers think about current models of ANNs as symbolic in nature.  Symbols 0 or 1 are used to "communicate" among neurons.  

Aanalog computing is not symbolic in its nature.



Neurology:
Biological NNs... neurons detect shapes.
<line 105 in ai.txt>
Sensory and hidden layer neurons functionality are the same.
Neurologists often model neural activity as one dimentional point processes with time labeling the axis.
<Muscle twitch>
Adaptation indicates detection thresholds are not constant.  On the other hand pain neuronal pathways are not learned and do not degrade over time.<citation wikipedia???>

Every voluntary answer your brain gives to any question is expressed in terms of the NOW symbol because it involves muscle movement.[3]  A muscle fiber only needs to know if it has to contract right NOW.  Biology dictates that the only correct question is "when should I twitch that muscle fiber?" and the answer is always now.  
<DELETE?  Now is also the best answer because all information available before now is taken into account.>

In a biological neural network over two hundred neurotransmitters can be found. If an analogy with ANN is drawn, over two hundred different messages or symbols can be sent or received by neurons. Connectionism does not address this variety of symbols processed by biological neurons. Mechanisms of changing internal state of a neuron are many and variable. Neuron's membrane potential can be changed via photons, chemical, electrical or mechanical means.  
These mechanisms are important but are not common to all types of cells.
The common principle is the detection of internal state change.

Once the mechanism of perception is accepted, one can argue about the mechanisms of state change. Wether they require inhibition. If synapses should be modeled as weights or oscillators.


In the context of Artificial Neural Network (ANN), one might argue that hidden layers percieve their inputs just as external stimuli are prerceived. In this case messages passed between neurons are not important. What is important is that change in the internal state of the neuron is detected. This fact drastically influences the ANN models. 

######################################################################

Why detection? What is wrong with measuring? Measurement is a projection of a real world phenomenon onto a number line.  A shadow. Although a measure might have a meaning for a single observer, it is meaningless to another observer unless units are agreed upon.  It is easier to understand perception through a mechanism where the first observer changes second observer's state without agreeing on units than transfering information in terms of numbers.  Unless one can come up with a mechanism how two observers agree on the units.

Still why is detection needed? Can't the second observer after it's state has been modified by the first go on to modify the third's observer state proportionally to it's own state change? Why does the second observer need to detect it's own state change? Why can't it continuosly change the third observer's state? This is similar to analog electronics where changing component's imput changes it's output.
It takes energy to change a state. This energy should not be expanded unless the second observer's state has changed. Otherwise by expanding this energy second observer changes it's own state non-deterministically. 
However a system needs to react to external stimuli and not just it's unit's random internal state changes.  Also second observer needs to reset it's state in such a way that when it's state is changed again, the net change can be detected.

This could be just a biological approach to minimize energy consumption (see Rashevsky's principle of Optimal Design) 
[For a set of prescribed biological functions an organism has the optimal possible design with respect to economy of material used, and energy expenditure, needed for the performance of the prescribed function.]

Detection is a way of thinking about mechanism of perception.  One of it's form is threshold detection.
Why consider detection mechanism? Assuming this model creates a framework for an exaustive search for rules of state modification. 
Algorithm of changining state changes itself over time. Synapses change over time.  Habbituation gives us a hint that detection algorithm can also change over time. How does the environment influence the change mechanism? Why is there an inhibiting mechanism?  

#######################################################################

On the importance of time in physics, engineering and other sciences:
In classical physics one wants to describe reality in terms of functions. For example in an experiment where a ball is moving left and right on a track the balls position is described as a function of time f(t). This description breaks down when something unaccouned for happens.  If the ball is picked up and later placed back on the track this can be defined as a discontinuity in f(t). This discontinuity can be described in terms of the time interval because math describes the world in an instance of time or as a function of time.
In Engineering proceses are often modeled by linear function on intervals of time. This function can even be fitted by linear regression. When linear approximation is used a time interval has to be defined.  This is similar to subsumption architecture in robotics where state machines describing non-linear behavior become valid during a period of time. Describing everything in a system in terms of time (perception/ internal representations /actions) fits well with techniques described above.


Digital Signal Processing:
How do you turn continuous into discrete? Sample it at even time intervals to produce time series or detect changes in the signal and record the amplitude and time of change.  As speed of an ADC converter increases, amplitude changes take on a set {-1,0,1} due to the limited resolution of sensors.  This fact is exploited in "One-bit Audio" encoding.
<ADD - continue the point>

Sampling a random process at an arbitrary frequency does not guarantee exceeding Nyquist frequency of a real world phenomenon. Oversampling at the maximum sensor frequency produces excessive amounts of data. Detecting signal changes after noise is filtered out guarantees to capture information needed to reproduce the signal.  For example a sensor sampling brightness 100 times per second produces 8,640,000 samples in 24 hours. This is excessive if the goal is to figure out if it is night or day. Given noise is not a problem, detecting changes produces the optimal sample rate to capture the signal.

Observing the signal via multiple observers that detect changes instead of sampling is a better model that uses the mechanism of perception.


Statistics:
In statistics mechanism of perception can be used to runs statistical experiments.  It allows one to go from observing random processes in real world to producing results of an experiment. Every time a change is detected, it produces an outcome in an experiment.

Imagine you are observing a toss of a fair coin in the air. There are several random processes that can be observed for example:
f(t) is the height of the coin in inches
g(t) is the hight of the coin in meters
h(t) is the angle of the coin relative to horizon in degrees
how does one create an experiment to check if the coin is fair? First one needs to pick values of the random processes that define an outcome of the experiment. Lets say f(t) = 0, g(t) = 0 and h(t) = 0.  In addition one needs to pick times t1, t2, t3, etc at which these random variables are realized.

<move to Neurology ???>Embodyment might be the whole reason for having a brain. 
<REVISE>
Embodyment allows conducting experiments with small changes.
A coin is laying on the road cars are passing by and push the coin around but it does not flip it appears that the coin always lays on one side. just observing it will give you a probability distribution where a coin always lands on one side.
<EDIT>
Importance of embodyment can be explained in terms of statistics: embodyment allows one to change the experiment instead of just observing it. Bertrand paradox Method of selection/realization/observation influences the distribution of the random variable.

Perception mechanism bridges observation of random processes (random variables dependent on time) and statistical experiments.  Detection triggers the start of a new experiment. as well as defines it (feature binding concept helps define the boundaries of experiment (set of random variables) Detection described in terms of point processes form a set of possible outcomes.
* Embodyment allows changing the experiment
* Relative frequncy of occurence of event is a measure of the probability. <reference wikipedia ???>
* The advantage of using a point process is that a single random variable describing the frequency of the events is defined apriori.

Data without a time component produces combinatorial explosion. Having time reduces the number of possible combination of random variable realizations. Only data produced during identical time intervals can be combined.  This data will exibit correlation without causality. Causality on the other side will express itself as correlation in data from different time intervals. To avoid inverse error one needs to specify that correlation of data from different time intervals does not imply causality. Also one can NOT illiminate correlation without cause for example by dimentionality reduction techniques. In order to reason this way one needs to establish these time intervals. This is much easier to do when all information is expressed in terms of time instances.


Conclusion:
The future directions of research aligned with my view on perception include neuromorphic computing, reservoir computing, BEAM robotics, study of coupled oscillators and point processes.  It is just as important to revisit and recosider classic reasearch with this new outlook on perception to find what was missed and correct assumptions.


References:
[1] Frank Rosenblat, The Perceptron, 1957
[2] Stephen Wolfram, New Kind of Science,  chapter 10 "Perception"
[3] https://www.ted.com/talks/daniel_wolpert_the_real_reason_for_brains
[4] https://en.wikipedia.org/wiki/Point_process
[5] https://en.wikipedia.org/wiki/Quantification_(science)
[6] https://en.wikipedia.org/wiki/Symbol_grounding_problem
<TODO: change ted and wikipedia links to paper links>



#########################################
Machine learning deals with data bypassing perception

Detecting a change is much more precise in time than sampling.  While sampling, the change could occur anywhere within the time period.  Detecting a change will most of the time result in a constant delay.  So does propagation of the information about an event through the environment. For example thunder after lightning.
Detection model does not suffer from undersampling below Nyquist's frequency. Although some events will appear as if they occured in an instant.

Observer1 detects a change in one unit. Observer2 detects a change in two units and so on.
