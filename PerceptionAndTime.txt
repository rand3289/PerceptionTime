Perception and time in Artificial Intelligence.
Andrey Makushkin
toandrey@yahoo.com
February 18, 2019

Summary:
Perception is detection of an internal state change described in terms of time.  Detection of state change should not be described by changing the state.  This paper tries to explain this statement through examples and references to existing literature as well as elaborate on the implications.

Introduction:
Current widely accepted definition of perception can be summarized as "perception is a change in internal state as a result of external stimuli". Author will refrain from providing references to these definitions. I will simply provide a counter-example: a rock's internal state can be changed by heating it.  It will have a short term memory of it because it remains hot for some time. Geologist have made careers out of studying long term memories of the rocks. It can also actuate by falling on a passer-by's head as a result of changing its state. However I hope no one will claim that the rock is alive or can perceive it's environment.
On the other hand inside a neuron a different process takes place. Neuron's state (it's membrane potential) is changed by external stimuli. External stimula constitutes sensory stimula or other neurons firing. When membrane potential reaches a certain voltage level it is detected and neuron fires.

Misunderstanding that state can describe perception is a result of the state-oriented view of the world as opposed to process-oriented. In the process-oriented view a change in a process can be described by when it happened as opposed to <REWISE> a symbol changing from A to B in the state-oriented view. In this case symbol can represent any property or quantity.

Before proceeding to explain how this relates to Artificial Intelligence, lets review some historical views on perception. One of the first well known models of perception are Plato's theory of forms and his "Allegory of the Cave". Plato describes objects being perceived as shadows without ever knowing their true form. Modern computers are prisoners in Plato's cave who see shadows of the real world. What are these shadows? They are numbers!  Numbers are projections of real world penomena onto a number line. Every time a measurement is made, a shadow is produced. What are the alternatives you ask? In Plato's terms they are forms. Computers can perceive the world in terms of forms by detecting them.  Forms can not be measured, described as a symbol, or transmitted.  In the field of Artificial Intelligence, plato's forms are known as features. In other words a feature is a mechanism of perception.  Features can be detected by current models and even used in a generative mode to create  pictures.

Are features the answer to perception? In many current models feature detection or absense is represented symbolically as 0 or 1. The problem with that is the "Symbol Grounding Problem".

Symbol grounding problem should not be just a red flag for symbolic AI but a red brick wall for any approach that uses state in it's computation model.  Current models of ANNs are also symbolic in nature.  Symbols 0 or 1 are used to "communicate" among neurons.  This has been addressed previously (insert reference to paper "On time") In a biological neural network over two hundred neurotransmitters can be found. If an analogy with ANN is drawn, over two hundred different messages or symbols can be sent or received by neurons. Connectionism does not address this variety of symbols processed by biological neurons. Mechanisms of changing internal state of a neuron are many and variable. Neuron's membrane potential can be changed via photons, chemical, electrical or mechanical means.  These mechanisms do not constitute the main priciples of operations. The main principle is the detection of internal state change.


Implications:

In the context of Artificial Neural Network (ANN), one might argue that hidden layers percieve their inputs just as external stimuli are prerceived. In this case messages passed between neurons are not important. What is important is that change in the internal state of the neuron is detected. This fact drastically influences the ANN models. 

Beam robotics, liquid state machines.
Aanalog computing is not symbolic in its nature.

